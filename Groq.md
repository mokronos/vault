
## First Impression

Seems to be just doing LLM inference, with a bunch of optimizations which makes it really fast. The optimizations seem proprietary but maybe one can guess if you read the newest research. But prices seem to be the cheapest as well compared to other open models (Llama, Mixtral, etc.) inference providers, so might be just a no brainer to use if you don't use the openai models. It's probably really difficult to compete on cost with a company that's sole focus is to only do llm inference.

## exllamav2

might be a local alternative